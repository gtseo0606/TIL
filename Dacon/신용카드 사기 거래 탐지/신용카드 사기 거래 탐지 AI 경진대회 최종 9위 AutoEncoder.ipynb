{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "a2bcba5f-002e-4f49-9622-ada6117faf0a",
      "metadata": {
        "id": "a2bcba5f-002e-4f49-9622-ada6117faf0a"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sbYGESQLYai",
        "outputId": "8ee4fda8-d944-4e6e-d227-f46a7a832f18"
      },
      "id": "1sbYGESQLYai",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b0d9b68-7102-4eca-9543-3b9b8acafc6e",
      "metadata": {
        "id": "2b0d9b68-7102-4eca-9543-3b9b8acafc6e"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from tqdm.auto import tqdm\n",
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "from torch.optim import Optimizer, AdamW\n",
        "from torch.optim.lr_scheduler import LambdaLR, CyclicLR, OneCycleLR\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# 모델 학습을 위해 CUDA 환경 설정. : 지피유 설정\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "id": "D4YXQkfxTJxO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ac05eae-46dd-41a7-f54a-48bb5a6f6e83"
      },
      "id": "D4YXQkfxTJxO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.21.1-py3-none-any.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 6.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 32.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 65.8 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
            "\u001b[K     |████████████████████████████████| 101 kB 12.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Installing collected packages: pyyaml, tokenizers, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.8.1 pyyaml-6.0 tokenizers-0.12.1 transformers-4.21.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc7df3f2-62d0-4499-a46e-47d01699def0",
      "metadata": {
        "id": "fc7df3f2-62d0-4499-a46e-47d01699def0"
      },
      "source": [
        "## 하이퍼파라미터"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3367399-9798-4e38-967b-fd2320b9a2b2",
      "metadata": {
        "id": "c3367399-9798-4e38-967b-fd2320b9a2b2"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 50\n",
        "LR = 1e-2\n",
        "BS = 16384 # 2의 제곱승꼴\n",
        "SEED = 41\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4254e860-ff82-43ba-bfa3-fcee4eb3ddbd",
      "metadata": {
        "id": "4254e860-ff82-43ba-bfa3-fcee4eb3ddbd"
      },
      "source": [
        "## 시드고정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "101a714b-71b6-4475-a4ce-fa5f98bc2731",
      "metadata": {
        "id": "101a714b-71b6-4475-a4ce-fa5f98bc2731"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "\n",
        "seed_everything(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05a4172e-5791-446f-9616-35c09d8bf25a",
      "metadata": {
        "id": "05a4172e-5791-446f-9616-35c09d8bf25a"
      },
      "source": [
        "## 데이터로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a62c78cd-4f40-4e98-b8a6-1b6f1d906b4d",
      "metadata": {
        "id": "a62c78cd-4f40-4e98-b8a6-1b6f1d906b4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17e2e12a-925f-412a-90c8-ce74c30eeb4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(113842, 30) (28462, 31) (142503, 30)\n"
          ]
        }
      ],
      "source": [
        "train = pd.read_csv('./drive/MyDrive/input/신용카드 사기 거래 탐지/train.csv')\n",
        "train = train.drop(columns=['ID'])\n",
        "val = pd.read_csv('./drive/MyDrive/input/신용카드 사기 거래 탐지/val.csv')\n",
        "val = val.drop(columns=['ID'])\n",
        "test = pd.read_csv('./drive/MyDrive/input/신용카드 사기 거래 탐지/test.csv')\n",
        "test = test.drop(columns=['ID'])\n",
        "\n",
        "print(train.shape, val.shape, test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac27ed36-8031-47a7-bd0d-a913513f2e8e",
      "metadata": {
        "id": "ac27ed36-8031-47a7-bd0d-a913513f2e8e"
      },
      "source": [
        "## 데이터셋 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16fd60a5-24e2-4539-bfd0-1c374a641699",
      "metadata": {
        "id": "16fd60a5-24e2-4539-bfd0-1c374a641699"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, df, eval_mode):\n",
        "        self.df = df\n",
        "        self.eval_mode = eval_mode\n",
        "        if self.eval_mode:\n",
        "            self.labels = self.df['Class'].values\n",
        "            self.df = self.df.drop(columns=['Class']).values\n",
        "        else:\n",
        "            self.df = self.df.values\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        if self.eval_mode:\n",
        "            x = torch.from_numpy(self.df[index]).type(torch.FloatTensor)\n",
        "            y = torch.FloatTensor([self.labels[index]])\n",
        "            return x, y\n",
        "        else:\n",
        "            self.x = self.df[index]\n",
        "            return torch.Tensor(self.x)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9d880481-1965-499d-9caa-fdfa8526f789",
      "metadata": {
        "id": "9d880481-1965-499d-9caa-fdfa8526f789"
      },
      "outputs": [],
      "source": [
        "train_dataset = MyDataset(df=train, eval_mode=False)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BS, shuffle=True, num_workers=6)\n",
        "\n",
        "val_dataset = MyDataset(df = val, eval_mode=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BS, shuffle=False, num_workers=6)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39962463-032f-490a-a76d-c03991795f38",
      "metadata": {
        "id": "39962463-032f-490a-a76d-c03991795f38"
      },
      "source": [
        "## 1D AutoEncoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 계층 정규화\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, hidden_size, eps=1e-5):\n",
        "        \"\"\"Construct a layernorm module in the TF style (epsilon inside the square root).\n",
        "        \"\"\"\n",
        "        super(LayerNorm, self).__init__()\n",
        "        self.weight = nn.Parameter(torch.ones(hidden_size))\n",
        "        self.bias = nn.Parameter(torch.zeros(hidden_size))\n",
        "        self.variance_epsilon = eps\n",
        "\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        self.weight.data.fill_(1.0)\n",
        "        self.bias.data.zero_()\n",
        "\n",
        "    def forward(self, x):\n",
        "        u = x.mean(-1, keepdim=True)\n",
        "        s = (x - u).pow(2).mean(-1, keepdim=True)\n",
        "        x = (x - u) / torch.sqrt(s + self.variance_epsilon) # 계층정규화 완료\n",
        "        return self.weight * x + self.bias # wx+b\n",
        "        \n",
        "# 활성화 함수\n",
        "class GELU(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n",
        "        \n",
        "class AutoEncoder1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AutoEncoder1, self).__init__()\n",
        "        \n",
        "        \n",
        "        self.ln = LayerNorm(5000)\n",
        "        self.ln1 = LayerNorm(3500)\n",
        "        self.ln2 = LayerNorm(2000)\n",
        "        self.ln3 = LayerNorm(1000)\n",
        "        \n",
        "        self.upblock1 = nn.Sequential(nn.Linear(30, 1000), nn.BatchNorm1d(1000),GELU())\n",
        "        self.upblock2 = nn.Sequential(nn.Linear(1000,2000), nn.BatchNorm1d(2000),GELU())\n",
        "        self.upblock3 = nn.Sequential(nn.Linear(2000,3500), nn.BatchNorm1d(3500),GELU())\n",
        "        self.upblock4 = nn.Sequential(nn.Linear(3500,5000), nn.BatchNorm1d(5000),GELU())\n",
        "\n",
        "        self.downblock1 = nn.Sequential(nn.Linear(5000, 3500),nn.BatchNorm1d(3500),GELU())\n",
        "        self.downblock2 = nn.Sequential(nn.Linear(3500, 2000),nn.BatchNorm1d(2000),GELU())\n",
        "        self.downblock3 = nn.Sequential(nn.Linear(2000, 1000),nn.BatchNorm1d(1000),GELU())\n",
        "        self.downblock4 = nn.Sequential(nn.Linear(1000, 300),nn.BatchNorm1d(300),GELU())\n",
        "        \n",
        "        self.fclayer = nn.Sequential(nn.Linear(300,30))\n",
        "        self.dropout = nn.Dropout(0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        upblock1_out = self.upblock1(x) \n",
        "        upblock2_out = self.upblock2(upblock1_out)\n",
        "        upblock3_out = self.upblock3(upblock2_out)\n",
        "        upblock4_out = self.upblock4(upblock3_out)\n",
        "        \n",
        "        downblock1_out = self.downblock1(self.ln(upblock4_out)) \n",
        "        skipblock1 = downblock1_out + upblock3_out \n",
        "        downblock2_out = self.downblock2(self.ln1(skipblock1))\n",
        "        skipblock2 = downblock2_out + upblock2_out\n",
        "        downblock3_out = self.downblock3(self.ln2(skipblock2))\n",
        "        skipblock3 = downblock3_out + upblock1_out \n",
        "        downblock4_out = self.downblock4(self.ln3(skipblock3))\n",
        "        \n",
        "        x = self.fclayer(downblock4_out)\n",
        "         \n",
        "        return x # 4"
      ],
      "metadata": {
        "id": "QtSaUCRKqt6-"
      },
      "id": "QtSaUCRKqt6-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "122af0aa-a1fd-4595-9488-35761e3cb596",
      "metadata": {
        "id": "122af0aa-a1fd-4595-9488-35761e3cb596"
      },
      "source": [
        "## Train (학습)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a17df6b3-16c9-44dd-b0fd-ffb501fee749",
      "metadata": {
        "id": "a17df6b3-16c9-44dd-b0fd-ffb501fee749"
      },
      "outputs": [],
      "source": [
        "class Trainer():\n",
        "    def __init__(self, model, optimizer, train_loader, val_loader, scheduler, device):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.scheduler = scheduler\n",
        "        self.device = device\n",
        "        # Loss Function\n",
        "        self.criterion = nn.L1Loss().to(self.device)\n",
        "        \n",
        "    def fit(self):\n",
        "        self.model.to(self.device)\n",
        "        best_score = 0\n",
        "        avg = 1\n",
        "        for epoch in range(EPOCHS):\n",
        "            self.model.train()\n",
        "            train_loss = []\n",
        "            for x in iter(self.train_loader):\n",
        "                x = x.float().to(self.device)\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                _x = self.model(x)\n",
        "                loss = self.criterion(x, _x)\n",
        "\n",
        "                loss.backward()\n",
        "                self.optimizer.step()\n",
        "\n",
        "                train_loss.append(loss.item())\n",
        "\n",
        "            score = self.validation(self.model, 0.95)\n",
        "            print(f'Epoch : [{epoch}] Train loss : [{np.mean(train_loss)}] Val Score : [{score}])')\n",
        "\n",
        "            if self.scheduler is not None:\n",
        "                self.scheduler.step(score)\n",
        "\n",
        "            if best_score <= score and avg > np.mean(train_loss):\n",
        "                best_score = score\n",
        "                avg = np.mean(train_loss)\n",
        "                torch.save(model.module.state_dict(), './best_model.pth', _use_new_zipfile_serialization=False)\n",
        "                print('---------------------------')\n",
        "                print(f'Train loss : [{np.mean(train_loss)}] Val Score : [{score}])')\n",
        "    \n",
        "    def validation(self, eval_model, thr):\n",
        "        cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "        eval_model.eval()\n",
        "        pred = []\n",
        "        true = []\n",
        "        with torch.no_grad():\n",
        "            for x, y in iter(self.val_loader):\n",
        "                x = x.float().to(self.device)\n",
        "\n",
        "                _x = self.model(x)\n",
        "                diff = cos(x, _x).cpu().tolist()\n",
        "                batch_pred = np.where(np.array(diff)<thr, 1, 0).tolist()\n",
        "                pred += batch_pred\n",
        "                true += y.tolist()\n",
        "\n",
        "        return f1_score(true, pred, average='macro')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51da39f9-904f-4abd-a7d2-cdf29c4a6c24",
      "metadata": {
        "id": "51da39f9-904f-4abd-a7d2-cdf29c4a6c24"
      },
      "source": [
        "## 모델 학습"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch, gc\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "jiqiaGRseZMI"
      },
      "id": "jiqiaGRseZMI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86142d9a-68b7-4d04-8423-49d28025411d",
      "metadata": {
        "tags": [],
        "id": "86142d9a-68b7-4d04-8423-49d28025411d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00d5fcc4-d7c8-481f-de2f-127037e1eefe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch : [0] Train loss : [0.5130304609026227] Val Score : [0.01770493016168002])\n",
            "---------------------------\n",
            "Train loss : [0.5130304609026227] Val Score : [0.01770493016168002])\n",
            "Epoch : [1] Train loss : [0.24234039655753545] Val Score : [0.2820413080318538])\n",
            "---------------------------\n",
            "Train loss : [0.24234039655753545] Val Score : [0.2820413080318538])\n",
            "Epoch : [2] Train loss : [0.1678934863635472] Val Score : [0.4936036828766804])\n",
            "---------------------------\n",
            "Train loss : [0.1678934863635472] Val Score : [0.4936036828766804])\n",
            "Epoch : [3] Train loss : [0.1274620837398938] Val Score : [0.5078511110326694])\n",
            "---------------------------\n",
            "Train loss : [0.1274620837398938] Val Score : [0.5078511110326694])\n",
            "Epoch : [4] Train loss : [0.10653261521032878] Val Score : [0.5133823628543464])\n",
            "---------------------------\n",
            "Train loss : [0.10653261521032878] Val Score : [0.5133823628543464])\n",
            "Epoch : [5] Train loss : [0.09249477088451385] Val Score : [0.5239044751074692])\n",
            "---------------------------\n",
            "Train loss : [0.09249477088451385] Val Score : [0.5239044751074692])\n",
            "Epoch : [6] Train loss : [0.0851219083581652] Val Score : [0.548274248222427])\n",
            "---------------------------\n",
            "Train loss : [0.0851219083581652] Val Score : [0.548274248222427])\n",
            "Epoch : [7] Train loss : [0.08238800721509117] Val Score : [0.5604091444190722])\n",
            "---------------------------\n",
            "Train loss : [0.08238800721509117] Val Score : [0.5604091444190722])\n",
            "Epoch : [8] Train loss : [0.07971146809203285] Val Score : [0.5742488678630496])\n",
            "---------------------------\n",
            "Train loss : [0.07971146809203285] Val Score : [0.5742488678630496])\n",
            "Epoch : [9] Train loss : [0.07644287177494594] Val Score : [0.6007476543609798])\n",
            "---------------------------\n",
            "Train loss : [0.07644287177494594] Val Score : [0.6007476543609798])\n",
            "Epoch : [10] Train loss : [0.07294492423534393] Val Score : [0.648669888934009])\n",
            "---------------------------\n",
            "Train loss : [0.07294492423534393] Val Score : [0.648669888934009])\n",
            "Epoch : [11] Train loss : [0.07072315258639199] Val Score : [0.7870308296420961])\n",
            "---------------------------\n",
            "Train loss : [0.07072315258639199] Val Score : [0.7870308296420961])\n",
            "Epoch : [12] Train loss : [0.06865123340061732] Val Score : [0.8202665410912253])\n",
            "---------------------------\n",
            "Train loss : [0.06865123340061732] Val Score : [0.8202665410912253])\n",
            "Epoch : [13] Train loss : [0.06595013397080558] Val Score : [0.8470287373843977])\n",
            "---------------------------\n",
            "Train loss : [0.06595013397080558] Val Score : [0.8470287373843977])\n",
            "Epoch : [14] Train loss : [0.06409070534365517] Val Score : [0.8674887641844412])\n",
            "---------------------------\n",
            "Train loss : [0.06409070534365517] Val Score : [0.8674887641844412])\n",
            "Epoch : [15] Train loss : [0.06162752264312336] Val Score : [0.8844834793761085])\n",
            "---------------------------\n",
            "Train loss : [0.06162752264312336] Val Score : [0.8844834793761085])\n",
            "Epoch : [16] Train loss : [0.06325199242149081] Val Score : [0.8967110829723166])\n",
            "Epoch : [17] Train loss : [0.061388706522328515] Val Score : [0.9031202878275757])\n",
            "---------------------------\n",
            "Train loss : [0.061388706522328515] Val Score : [0.9031202878275757])\n",
            "Epoch : [18] Train loss : [0.059044002422264645] Val Score : [0.9097393418694286])\n",
            "---------------------------\n",
            "Train loss : [0.059044002422264645] Val Score : [0.9097393418694286])\n",
            "Epoch : [19] Train loss : [0.0571300382060664] Val Score : [0.9097393418694286])\n",
            "---------------------------\n",
            "Train loss : [0.0571300382060664] Val Score : [0.9097393418694286])\n",
            "Epoch : [20] Train loss : [0.05564544882093157] Val Score : [0.9097393418694286])\n",
            "---------------------------\n",
            "Train loss : [0.05564544882093157] Val Score : [0.9097393418694286])\n",
            "Epoch : [21] Train loss : [0.05437892835055079] Val Score : [0.9097393418694286])\n",
            "---------------------------\n",
            "Train loss : [0.05437892835055079] Val Score : [0.9097393418694286])\n",
            "Epoch : [22] Train loss : [0.05074142611452511] Val Score : [0.9097393418694286])\n",
            "---------------------------\n",
            "Train loss : [0.05074142611452511] Val Score : [0.9097393418694286])\n",
            "Epoch : [23] Train loss : [0.049483196543795724] Val Score : [0.9165787375726882])\n",
            "---------------------------\n",
            "Train loss : [0.049483196543795724] Val Score : [0.9165787375726882])\n",
            "Epoch : [24] Train loss : [0.049338934144803455] Val Score : [0.9097393418694286])\n",
            "Epoch : [25] Train loss : [0.04710444435477257] Val Score : [0.9165787375726882])\n",
            "---------------------------\n",
            "Train loss : [0.04710444435477257] Val Score : [0.9165787375726882])\n",
            "Epoch : [26] Train loss : [0.04552343913487026] Val Score : [0.9165787375726882])\n",
            "---------------------------\n",
            "Train loss : [0.04552343913487026] Val Score : [0.9165787375726882])\n",
            "Epoch : [27] Train loss : [0.04627137098993574] Val Score : [0.9165787375726882])\n",
            "Epoch : [28] Train loss : [0.04821250907012394] Val Score : [0.9165787375726882])\n",
            "Epoch : [29] Train loss : [0.04832304269075394] Val Score : [0.9165787375726882])\n",
            "Epoch : [30] Train loss : [0.04642792312162263] Val Score : [0.9165787375726882])\n",
            "Epoch : [31] Train loss : [0.044996224875961034] Val Score : [0.9165787375726882])\n",
            "---------------------------\n",
            "Train loss : [0.044996224875961034] Val Score : [0.9165787375726882])\n",
            "Epoch : [32] Train loss : [0.0425546903695379] Val Score : [0.9165787375726882])\n",
            "---------------------------\n",
            "Train loss : [0.0425546903695379] Val Score : [0.9165787375726882])\n",
            "Epoch : [33] Train loss : [0.042287194303103855] Val Score : [0.9165787375726882])\n",
            "---------------------------\n",
            "Train loss : [0.042287194303103855] Val Score : [0.9165787375726882])\n",
            "Epoch : [34] Train loss : [0.04213143406169755] Val Score : [0.9165787375726882])\n",
            "Epoch 00035: reducing learning rate of group 0 to 5.0000e-03.\n",
            "---------------------------\n",
            "Train loss : [0.04213143406169755] Val Score : [0.9165787375726882])\n",
            "Epoch : [35] Train loss : [0.037202970790011544] Val Score : [0.9165787375726882])\n",
            "---------------------------\n",
            "Train loss : [0.037202970790011544] Val Score : [0.9165787375726882])\n",
            "Epoch : [36] Train loss : [0.03487754027758326] Val Score : [0.9165787375726882])\n",
            "---------------------------\n",
            "Train loss : [0.03487754027758326] Val Score : [0.9165787375726882])\n",
            "Epoch : [37] Train loss : [0.033436503793512075] Val Score : [0.9165787375726882])\n",
            "---------------------------\n",
            "Train loss : [0.033436503793512075] Val Score : [0.9165787375726882])\n",
            "Epoch : [38] Train loss : [0.03292071207293442] Val Score : [0.9165787375726882])\n",
            "---------------------------\n",
            "Train loss : [0.03292071207293442] Val Score : [0.9165787375726882])\n",
            "Epoch : [39] Train loss : [0.03361827347959791] Val Score : [0.9165787375726882])\n",
            "Epoch : [40] Train loss : [0.03204497428877013] Val Score : [0.9165787375726882])\n",
            "---------------------------\n",
            "Train loss : [0.03204497428877013] Val Score : [0.9165787375726882])\n",
            "Epoch : [41] Train loss : [0.032481760318790166] Val Score : [0.9165787375726882])\n",
            "Epoch : [42] Train loss : [0.032075253182223866] Val Score : [0.9165787375726882])\n",
            "Epoch : [43] Train loss : [0.03242022331271853] Val Score : [0.9165787375726882])\n",
            "Epoch : [44] Train loss : [0.03197772694485528] Val Score : [0.9165787375726882])\n",
            "---------------------------\n",
            "Train loss : [0.03197772694485528] Val Score : [0.9165787375726882])\n",
            "Epoch : [45] Train loss : [0.03289415075310639] Val Score : [0.9165787375726882])\n",
            "Epoch 00046: reducing learning rate of group 0 to 2.5000e-03.\n",
            "Epoch : [46] Train loss : [0.03009534254670143] Val Score : [0.9165787375726882])\n",
            "---------------------------\n",
            "Train loss : [0.03009534254670143] Val Score : [0.9165787375726882])\n",
            "Epoch : [47] Train loss : [0.02849389346582549] Val Score : [0.9165787375726882])\n",
            "---------------------------\n",
            "Train loss : [0.02849389346582549] Val Score : [0.9165787375726882])\n",
            "Epoch : [48] Train loss : [0.027821061334439685] Val Score : [0.9165787375726882])\n",
            "---------------------------\n",
            "Train loss : [0.027821061334439685] Val Score : [0.9165787375726882])\n",
            "Epoch : [49] Train loss : [0.027321371116808484] Val Score : [0.9165787375726882])\n",
            "---------------------------\n",
            "Train loss : [0.027321371116808484] Val Score : [0.9165787375726882])\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "model = nn.DataParallel(AutoEncoder1())\n",
        "model.eval()\n",
        "\n",
        "#optimizer = AdamW(params = model.parameters(), lr = LR, eps=1e-06)\n",
        "optimizer = torch.optim.Adam(params = model.parameters(), lr = LR)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10, threshold_mode='abs', min_lr=1e-8, verbose=True)\n",
        "\n",
        "#scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.00005, step_size_up=5, max_lr=0.001, gamma=0.5, mode='exp_range', cycle_momentum=False)\n",
        "\n",
        "trainer = Trainer(model, optimizer, train_loader, val_loader, scheduler, device)\n",
        "trainer.fit()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.memory_summary(device=None, abbreviated=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "id": "CXGFu4gSkaDY",
        "outputId": "330687d5-c378-4df1-be1e-800408ef6bbf"
      },
      "id": "CXGFu4gSkaDY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |    1639 MB |   11821 MB |  154233 GB |  154232 GB |\\n|       from large pool |    1635 MB |   11816 MB |  154202 GB |  154200 GB |\\n|       from small pool |       3 MB |       5 MB |      31 GB |      31 GB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |    1639 MB |   11821 MB |  154233 GB |  154232 GB |\\n|       from large pool |    1635 MB |   11816 MB |  154202 GB |  154200 GB |\\n|       from small pool |       3 MB |       5 MB |      31 GB |      31 GB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |   12522 MB |   12552 MB |   54616 MB |   42094 MB |\\n|       from large pool |   12516 MB |   12546 MB |   54602 MB |   42086 MB |\\n|       from small pool |       6 MB |       6 MB |      14 MB |       8 MB |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory |    1060 MB |    1634 MB |   19799 GB |   19798 GB |\\n|       from large pool |    1060 MB |    1633 MB |   19712 GB |   19711 GB |\\n|       from small pool |       0 MB |       2 MB |      86 GB |      86 GB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |     389    |     484    |    1945 K  |    1945 K  |\\n|       from large pool |      60    |     130    |    1178 K  |    1178 K  |\\n|       from small pool |     329    |     357    |     767 K  |     767 K  |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |     389    |     484    |    1945 K  |    1945 K  |\\n|       from large pool |      60    |     130    |    1178 K  |    1178 K  |\\n|       from small pool |     329    |     357    |     767 K  |     767 K  |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |      77    |      82    |     323    |     246    |\\n|       from large pool |      74    |      79    |     316    |     242    |\\n|       from small pool |       3    |       3    |       7    |       4    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |      24    |      84    |    1116 K  |    1116 K  |\\n|       from large pool |      22    |      78    |     786 K  |     786 K  |\\n|       from small pool |       2    |      29    |     330 K  |     330 K  |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "41ee1a4c-afe9-4f3c-a3f6-3bca5eb2109f",
      "metadata": {
        "id": "41ee1a4c-afe9-4f3c-a3f6-3bca5eb2109f"
      },
      "source": [
        "## 추론"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c53e6313-382b-4f31-a587-1824c579abb7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c53e6313-382b-4f31-a587-1824c579abb7",
        "outputId": "05cf7119-0781-4e61-bcb3-43a91a2cf90c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataParallel(\n",
              "  (module): AutoEncoder1(\n",
              "    (ln): LayerNorm()\n",
              "    (ln1): LayerNorm()\n",
              "    (ln2): LayerNorm()\n",
              "    (ln3): LayerNorm()\n",
              "    (upblock1): Sequential(\n",
              "      (0): Linear(in_features=30, out_features=1000, bias=True)\n",
              "      (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): GELU()\n",
              "    )\n",
              "    (upblock2): Sequential(\n",
              "      (0): Linear(in_features=1000, out_features=2000, bias=True)\n",
              "      (1): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): GELU()\n",
              "    )\n",
              "    (upblock3): Sequential(\n",
              "      (0): Linear(in_features=2000, out_features=3500, bias=True)\n",
              "      (1): BatchNorm1d(3500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): GELU()\n",
              "    )\n",
              "    (upblock4): Sequential(\n",
              "      (0): Linear(in_features=3500, out_features=5000, bias=True)\n",
              "      (1): BatchNorm1d(5000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): GELU()\n",
              "    )\n",
              "    (downblock1): Sequential(\n",
              "      (0): Linear(in_features=5000, out_features=3500, bias=True)\n",
              "      (1): BatchNorm1d(3500, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): GELU()\n",
              "    )\n",
              "    (downblock2): Sequential(\n",
              "      (0): Linear(in_features=3500, out_features=2000, bias=True)\n",
              "      (1): BatchNorm1d(2000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): GELU()\n",
              "    )\n",
              "    (downblock3): Sequential(\n",
              "      (0): Linear(in_features=2000, out_features=1000, bias=True)\n",
              "      (1): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): GELU()\n",
              "    )\n",
              "    (downblock4): Sequential(\n",
              "      (0): Linear(in_features=1000, out_features=300, bias=True)\n",
              "      (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (2): GELU()\n",
              "    )\n",
              "    (fclayer): Sequential(\n",
              "      (0): Linear(in_features=300, out_features=30, bias=True)\n",
              "    )\n",
              "    (dropout): Dropout(p=0.2, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "model = AutoEncoder1()\n",
        "model.load_state_dict(torch.load('./best_model.pth'))\n",
        "model = nn.DataParallel(model)\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65628d5a-dedd-4525-8f9d-ba3f00de9eee",
      "metadata": {
        "id": "65628d5a-dedd-4525-8f9d-ba3f00de9eee"
      },
      "outputs": [],
      "source": [
        "test = pd.read_csv('./drive/MyDrive/input/신용카드 사기 거래 탐지/test.csv')\n",
        "test = test.drop(columns=['ID'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e87c859b-be5a-426b-8a02-08ff5b38f1bc",
      "metadata": {
        "id": "e87c859b-be5a-426b-8a02-08ff5b38f1bc"
      },
      "outputs": [],
      "source": [
        "test_dataset = MyDataset(test, False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BS, shuffle=False, num_workers=6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82bb801c-9207-4e2d-a44e-1b86eab8ff6e",
      "metadata": {
        "id": "82bb801c-9207-4e2d-a44e-1b86eab8ff6e"
      },
      "outputs": [],
      "source": [
        "def prediction(model, thr, test_loader, device):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "    pred = []\n",
        "    with torch.no_grad():\n",
        "        for x in iter(test_loader):\n",
        "            x = x.float().to(device)\n",
        "            _x = model(x)\n",
        "            \n",
        "            diff = cos(x, _x).cpu().tolist()\n",
        "            batch_pred = np.where(np.array(diff)<thr, 1,0).tolist()\n",
        "            pred += batch_pred\n",
        "    return pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d85fcc2-a3a7-451c-878f-8a0bb105c4cf",
      "metadata": {
        "id": "6d85fcc2-a3a7-451c-878f-8a0bb105c4cf"
      },
      "outputs": [],
      "source": [
        "preds = prediction(model, 0.95, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7ff9df77-6591-441d-a4ce-1a0aacc8f8df",
      "metadata": {
        "id": "7ff9df77-6591-441d-a4ce-1a0aacc8f8df"
      },
      "outputs": [],
      "source": [
        "submit = pd.read_csv('./drive/MyDrive/input/신용카드 사기 거래 탐지/sample_submission.csv')\n",
        "submit['Class'] = preds\n",
        "submit.to_csv('./submit_autoencoder2.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "신용카드_사기_거래_탐지_AI_경진대회_최종 9위 AutoEncoder.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}