{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2021-09-13\t응답 API 개발 - 데이터 전처리, 모델 예측.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPXJtwTZscji",
        "outputId": "1e10ac7b-b55a-434d-c475-80b8b94d5ede"
      },
      "source": [
        "!pip install flask-ngrok"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.7/dist-packages (0.0.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (2.23.0)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.7/dist-packages (from flask-ngrok) (1.1.4)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (2.11.3)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (1.0.1)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from Flask>=0.8->flask-ngrok) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->Flask>=0.8->flask-ngrok) (2.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->flask-ngrok) (2.10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0mFcqm7siP2",
        "outputId": "af811c31-2234-4f76-b5dd-d007738153c5"
      },
      "source": [
        "# 웹서버 제작\n",
        "from flask import Flask\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "app = Flask(__name__)\n",
        "run_with_ngrok(app) #app(flask)의 권한을 ngrok에 넘겨줌\n",
        "\n",
        "@app.route(\"/\")\n",
        "def home():\n",
        "  return \"<h1>This is your Flask server.</h1>\"\n",
        "\n",
        "app.run()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://32a5-34-125-117-129.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKRbjMzrsiUP",
        "outputId": "caad50a1-807e-44b0-a7b3-1f59a187acb4"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mlp_v0.1.h5  sample_data  submit_form.html  submit_form.html.txt  X.csv  y.npy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc-5v2eXsiYo",
        "outputId": "77659fe2-9fef-4fa0-a962-0a6626a4892f"
      },
      "source": [
        "# 웹서버 제작\n",
        "from flask import Flask, render_template, request\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "app = Flask(__name__, template_folder='/content')\n",
        "run_with_ngrok(app) #app(flask)의 권한을 ngrok에 넘겨줌\n",
        "\n",
        "@app.route(\"/\")\n",
        "def predict():\n",
        "  #return \"<h1>This is your Flask server.</h1>\"\n",
        "  return render_template(\"submit_form.html\")\n",
        "\n",
        "@app.route(\"/result\", methods=[\"POST\"])\n",
        "def result():\n",
        "  # data 읽기\n",
        "  # 데이터 전처리\n",
        "  # Model prediction\n",
        "  # Return prediction\n",
        "\n",
        "\n",
        "  #data = request.form\n",
        "\n",
        "  message = \"\"\n",
        "  message += \"<h1>House Price</h1>\"\n",
        "\n",
        "  # for k,v in data.items():\n",
        "  #   print(k, v)\n",
        "  #   message += k + \": \" + v + \"</br>\"\n",
        "\n",
        "  return message\n",
        "\n",
        "app.run()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://f05f-34-125-117-129.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBhIFW7StjV3"
      },
      "source": [
        "# Train MLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f18UB95PsihG"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFLTnZWmsikP",
        "outputId": "adaa7099-d19d-444e-b1ff-2640d9bd40d4"
      },
      "source": [
        "!pip list | grep tensorflow"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensorflow                    2.6.0\n",
            "tensorflow-datasets           4.0.1\n",
            "tensorflow-estimator          2.6.0\n",
            "tensorflow-gcs-config         2.6.0\n",
            "tensorflow-hub                0.12.0\n",
            "tensorflow-metadata           1.2.0\n",
            "tensorflow-probability        0.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBSorXJltsUm"
      },
      "source": [
        "## preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhmh9LEmsinP"
      },
      "source": [
        "# load data\n",
        "X = pd.read_csv('X.csv')\n",
        "\n",
        "with open('y.npy', 'rb') as f:\n",
        "    y = np.load(f)\n",
        "\n",
        "# OverallQual 10\n",
        "# GrLivArea 10\n",
        "# GarageCars 9\n",
        "# GarageArea 8\n",
        "# TotalBsmtSF 7\n",
        "# 1stFlrSF 6\n",
        "# FullBath 5\n",
        "# LotShape Reg\n",
        "X = X[['OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea', 'TotalBsmtSF', '1stFlrSF', 'FullBath', 'LotShape_rank']]\n",
        "\n",
        "x_min_max_scaler = MinMaxScaler()\n",
        "x_min_max_scaler.fit(X)\n",
        "scaled_X = x_min_max_scaler.transform(X)\n",
        "\n",
        "y_min_max_scaler = MinMaxScaler()\n",
        "y_min_max_scaler.fit(y)\n",
        "scaled_y = y_min_max_scaler.transform(y)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MI9JijxOtu3Y"
      },
      "source": [
        "## training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FhEvW2SxsiqC",
        "outputId": "76026446-0139-48e6-c271-2d1f40473fdf"
      },
      "source": [
        "model = keras.Sequential(\n",
        "      [\n",
        "          keras.Input(shape=scaled_X.shape[-1]),\n",
        "          layers.Dense(96, activation='relu'),\n",
        "          layers.Dense(48, activation='relu'),\n",
        "          layers.Dense(1)\n",
        "      ]\n",
        "  )\n",
        "\n",
        "model.compile(loss=\"mse\", optimizer=\"adam\")\n",
        "\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15)\n",
        "model.fit(scaled_X, scaled_y, \n",
        "          batch_size=2, epochs=150, \n",
        "          callbacks=[early_stopping_callback], validation_split=0.05)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "694/694 [==============================] - 2s 2ms/step - loss: 0.0043 - val_loss: 0.0017\n",
            "Epoch 2/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0035 - val_loss: 0.0015\n",
            "Epoch 3/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0033 - val_loss: 0.0014\n",
            "Epoch 4/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0030 - val_loss: 0.0016\n",
            "Epoch 5/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0028 - val_loss: 0.0014\n",
            "Epoch 6/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0027 - val_loss: 0.0014\n",
            "Epoch 7/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0026 - val_loss: 0.0013\n",
            "Epoch 8/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0025 - val_loss: 0.0014\n",
            "Epoch 9/150\n",
            "694/694 [==============================] - 1s 2ms/step - loss: 0.0025 - val_loss: 0.0014\n",
            "Epoch 10/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0024 - val_loss: 0.0012\n",
            "Epoch 11/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0023 - val_loss: 0.0014\n",
            "Epoch 12/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0025 - val_loss: 0.0013\n",
            "Epoch 13/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0022 - val_loss: 0.0017\n",
            "Epoch 14/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0023 - val_loss: 0.0013\n",
            "Epoch 15/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0022 - val_loss: 0.0012\n",
            "Epoch 16/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0021 - val_loss: 0.0014\n",
            "Epoch 17/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0023 - val_loss: 0.0013\n",
            "Epoch 18/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0022 - val_loss: 0.0019\n",
            "Epoch 19/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0023 - val_loss: 0.0013\n",
            "Epoch 20/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0026 - val_loss: 0.0016\n",
            "Epoch 21/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0024 - val_loss: 0.0012\n",
            "Epoch 22/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0022 - val_loss: 0.0012\n",
            "Epoch 23/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0024 - val_loss: 0.0016\n",
            "Epoch 24/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0023 - val_loss: 0.0014\n",
            "Epoch 25/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0020 - val_loss: 0.0012\n",
            "Epoch 26/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0022 - val_loss: 0.0014\n",
            "Epoch 27/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0021 - val_loss: 0.0018\n",
            "Epoch 28/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0021 - val_loss: 0.0012\n",
            "Epoch 29/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0022 - val_loss: 0.0013\n",
            "Epoch 30/150\n",
            "694/694 [==============================] - 1s 1ms/step - loss: 0.0020 - val_loss: 0.0013\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2e2b21bd90>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oonG_JpjsitX"
      },
      "source": [
        "pred = model.predict(scaled_X[:1]) # 0 ~ 1\n",
        "pred = y_min_max_scaler.inverse_transform(pred)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRwjA6Q8t5RI"
      },
      "source": [
        "## Save MLP model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qM1L-5eAsiv_"
      },
      "source": [
        "model.save(\"mlp_v0.1.h5\")"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZHuifWYKsi4B"
      },
      "source": [
        "reconstructed_model = keras.models.load_model(\"mlp_v0.1.h5\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hya-dmTsi5w"
      },
      "source": [
        "pred = reconstructed_model.predict(scaled_X[:1]) # 0 ~ 1\n",
        "pred = y_min_max_scaler.inverse_transform(pred)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STW3QokEsi7y",
        "outputId": "ff33dab5-784b-4ef3-ee26-ff46adb713f5"
      },
      "source": [
        "pred"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[190533.75]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0pud3Howt--S"
      },
      "source": [
        "# Flask server"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkYpLkEQsi-S",
        "outputId": "0cfd70e2-9096-4f75-bc55-790022f302b2"
      },
      "source": [
        "from flask import Flask, render_template, request\n",
        "from flask_ngrok import run_with_ngrok\n",
        "\n",
        "# load data\n",
        "X = pd.read_csv('X.csv')\n",
        "\n",
        "with open('y.npy', 'rb') as f:\n",
        "    y = np.load(f)\n",
        "\n",
        "# OverallQual 10\n",
        "# GrLivArea 10\n",
        "# GarageCars 9\n",
        "# GarageArea 8\n",
        "# TotalBsmtSF 7\n",
        "# 1stFlrSF 6\n",
        "# FullBath 5\n",
        "# LotShape Reg\n",
        "X = X[['OverallQual', 'GrLivArea', 'GarageCars', 'GarageArea', 'TotalBsmtSF', '1stFlrSF', 'FullBath', 'LotShape_rank']]\n",
        "\n",
        "x_min_max_scaler = MinMaxScaler()\n",
        "x_min_max_scaler.fit(X)\n",
        "\n",
        "y_min_max_scaler = MinMaxScaler()\n",
        "y_min_max_scaler.fit(y)\n",
        "\n",
        "# load model\n",
        "reconstructed_model = keras.models.load_model(\"mlp_v0.1.h5\")\n",
        "\n",
        "# run server\n",
        "app = Flask(__name__, template_folder='/content')\n",
        "run_with_ngrok(app)\n",
        "\n",
        "def preprocess_data(data):\n",
        "  # return np.zeros((1, 8)) # dummy data\n",
        "\n",
        "  \"\"\"\n",
        "  Dictionary --> np array (1, 8)\n",
        "\n",
        "  OverallQual 2\n",
        "  GrLivArea 5000\n",
        "  GarageCars 2\n",
        "  GarageArea 480\n",
        "  TotalBsmtSF 991\n",
        "  1stFlrSF 1087\n",
        "  FullBath 2\n",
        "  LotShape IR3 --> 1, 2, 3, 4\n",
        "  \"\"\"\n",
        "  X = [] # <-- OverallQual, GrLivArea, ... LotShape\n",
        "  for k, v in data.items():\n",
        "    if k == 'LotShape':\n",
        "      if v == 'Reg':\n",
        "        X.append(4)\n",
        "      elif v == 'IR1':\n",
        "        X.append(3)\n",
        "      elif v == 'IR2':\n",
        "        X.append(2)\n",
        "      elif v == 'IR3':\n",
        "        X.append(1)\n",
        "    else:\n",
        "      X.append(float(v))\n",
        "\n",
        "  # X = [2, 5000, 2, ... , 3]\n",
        "  X = np.array(X) # (8,)\n",
        "  X = X.reshape((1, -1)) # (1, 8)\n",
        "\n",
        "  # min max scaling\n",
        "  scaled_X = x_min_max_scaler.transform(X)\n",
        "\n",
        "  return scaled_X\n",
        "  \n",
        "@app.route(\"/\")\n",
        "def predict():\n",
        "  #return \"<h1>This is your Flask server.</h1>\"\n",
        "  return render_template(\"submit_form.html\")\n",
        "\n",
        "@app.route(\"/result\", methods=['POST'])\n",
        "def result():\n",
        "  # Read data [v]\n",
        "  # Proprocess data \n",
        "  # Model prediction\n",
        "  # Return prediction\n",
        "\n",
        "  data = request.form # User data\n",
        "\n",
        "  message = \"\"\n",
        "  message += \"<h1>House Price</h1>\"\n",
        "\n",
        "  for k, v in data.items():\n",
        "    print(k, v)\n",
        "    message += k + \": \" + v + \"</br>\"\n",
        "\n",
        "  # 데이터 전처리\n",
        "  X = preprocess_data(data) # User data --> (1, 8) array\n",
        "\n",
        "  pred = reconstructed_model.predict(X)\n",
        "  pred = y_min_max_scaler.inverse_transform(pred)\n",
        "  # array (1, 1) --> string\n",
        "\n",
        "  message += \"</br>\"\n",
        "  message += \"Predicted price: \" + str(pred[0][0])\n",
        "\n",
        "  return message\n",
        "    \n",
        "app.run()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app \"__main__\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Running on http://0283-34-125-117-129.ngrok.io\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        }
      ]
    }
  ]
}
